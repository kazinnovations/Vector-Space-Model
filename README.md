Abstract: Big Data is a term which is used to describe massive amount of data generating from digital sources or the internet. From the past few years data is exponentially growing due to the use of connected devices such as smart phoneâ€™s, tablets, laptops and desktop computer. Moreover E-commerce which is also known as online market, internet services and social networking sites are generating tremendous user data in the form of documents, emails and web pages. This generated data volume is so vast and overwhelming which makes complex to process and analyze using traditional software systems consuming more time. This project presents a pre-processing algorithm to extract real time user accessed data from windows operating system environment.
Text Pre-processing is an important task and critical step in Text mining, Natural Language Processing and information retrieval. In the area of Text Mining, data pre-processing used for extracting interesting and non-trivial and knowledge from unstructured text data. Information Retrieval is essentially a matter of deciding which documents in a collection should be retrieved to satisfy a user's need for information. The user's need for information is represented by a query or profile, and contains one or more search terms, plus some additional information such as weight of the words. Hence, the retrieval decision is made by comparing the terms of the query with the index appearing in the document itself. The decision may be binary (retrieve/reject), or it may involve estimating the degree of relevance that the document has to query. Unfortunately, the words that appear in documents and in queries often have many structural variants. So, before the information retrieval from the documents, the data pre-processing techniques are applied on the target data set to reduce the size of the data set which will increase the effectiveness of IR System The objective of this project is to analyze the issues of pre-processing methods such as Tokenization, Stop word removal, Term weighting and to obtain the result in shot time.

Design: In this project we aim in doing the efficient information retrieval system, which will fetch the document from the set of documents or dataset provided by using the query. Here we provide the query along with the input documents and those queries will be the form of a text document and that will be compared and the result will be printed along with the magnitude of the document, query and the result showing 0 or 1, which shows the presence or absence of the query in the document or dataset. The screenshots provided below are the set of results given according the different variance of inputs and the expected outputs. The stages in the results will be as similar in all the cases, as we go further we will see the first stage as reading the dataset and the creation of the dataset, creation of the inverted index, along with creation of the TF*IDF of the weight vectors. Later those values will be used for comparison and accordingly the output is generated.
In this project we can give the different set of dataset in mean time and can be compared with n number of documents and the result will be the presence or absence of the same in the dataset. Also there is a backend process carrying out which is done through the Print Writer function used in JAVA, which will copy the console output to a new text file, and the encoding format is maintained. In the file we will get the weighted results of all the relevant terms used in the dataset, and the advantage is the stop words will be removed. There will one more document which will copy all the reading datasets to the new file so that at any stage of process we can check the documents used for comparison.

Future Enhancement: The implementation of the vector space model is an advanced topic in Hadoop platform, where the modern framework Mahout gives the best implementation of the vector representation. For clustering documents it is necessary to convert the raw text into vectors that can then be consumed by the clustering algorithms. Parallel computations reduces apparent complexity. Mahout has utilities that allow one to easily produce Mahout Vector representations from a Lucene (and Solr, since they are the same) index. We are here analyzing the project on both normal windows & Mahout Platforms.
